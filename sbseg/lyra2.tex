\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{framed}
\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{fancyvrb}
\usepackage{tabularx}
\usepackage{datetime}
\usepackage{algorithmic}
\usepackage[boxed]{algorithm}
\usepackage{anysize}
\usepackage{alltt}
\usepackage{sbc-template}
\usepackage{url,longtable,booktabs}

\begin{document}

\title{Implementação eficiente em \emph{software}\\ da função Lyra2 em arquiteturas modernas}

\author{Guilherme P. Gonçalves\inst{1}, Diego F. Aranha\inst{1}}

\address{Laboratório de Segurança e Criptografia (LASCA)\\
	Instituto de Computação (IC) -- Universidade Estadual de Campinas (Unicamp)\\
	Av. Albert Einstein, 1251 -- Campinas/SP -- Brasil\vspace{-0.25cm}
	\email{guilherme.p.gonc@gmail.com,dfaranha@ic.unicamp.br}\vspace{-0.25cm}
}

\maketitle

\begin{abstract}
Password authentication has become even more challenging with the significant increase
in available computing power by means of dedicated hardware and GPUs. This work
presents an efficient software implementation of the password hashing scheme Lyra2 in modern Intel platforms,
according to version 2.5 of its specification. The resulting implementation employs
AVX2 vector instructions for a performance improvement of 30\% over the reference
implementation. In practice, it is important to know the precise performance of such primitives to inform
parameter choice and corresponding security guarantees.
\vspace{-0.25cm}
\end{abstract}

\begin{resumo}
O problema de autenticação por senha tem se tornado cada vez mais desafiador, face ao crescimento
significativo de poder computacional na forma de \emph{hardware} dedicado e placas gráficas.
Este trabalho apresenta uma implementação eficiente em \emph{software} do esquema de \emph{hash} de senhas Lyra2 em arquiteturas Intel modernas,
conforme a versão 2.5 de sua especificação. A implementação resultante emprega instruções vetoriais AVX2
para ganhos de desempenho em torno de 30\% sobre a implementação de referência. Na prática, é importante
determinar precisamente o desempenho de primitivas dessa natureza para informar a escolha de parâmetros
e obter garantias de segurança.\vspace{-0.1cm}
\end{resumo}

\section{Introdução}

A forma mais comum de autenticação de usuários em sistemas
computacionais atualmente é o uso de senhas. Nesse paradigma, o usuário
é responsável por escolher uma senha ao se registrar, que deve
permanecer secreta, e o sistema verifica, a cada acesso, se o usuário
conhece a senha correta. Isso implica, é claro, o armazenamento da senha
de alguma forma no sistema.
%
Como medida de segurança, recomenda-se não armazenar a senha conforme
fornecida pelo usuário, mas sim um valor produzido por um esquema
de \emph{hash} de senhas. O \emph{hash} produz uma sequência pseudoaleatória
de \emph{bits} tal que, dado o valor de \emph{hash} $h$ de uma senha
$s$, deve ser computacionalmente difícil descobrir qualquer senha
(incluindo $s$) cujo \emph{hash} também seja $h$ -- uma propriedade
conhecida como resistência ao cálculo de pré-imagem.
Assim, em um mecanismo de autenticação moderno, o sistema calcula o
\emph{hash} da senha provida pelo usuário e o compara com o \emph{hash}
que havia sido armazenado durante o registro. Caso os
\emph{hashes} sejam iguais, o acesso é autorizado.

Muitas técnicas foram introduzidas para dificultar
ataques de busca exaustiva -- aqueles em que um atacante faz tentativas
sucessivas de adivinhar uma senha -- sem onerar usuários exigindo que
criem e memorizem senhas longas e suficientemente entrópicas.
No campo dos esquemas de \emph{hash} de senhas, isso significa a inclusão
de parâmetros de tempo e espaço de memória mínimos a serem utilizados
pela operação de \emph{hash}. O parâmetro de tempo impõe um limite à
velocidade com que um atacante pode fazer tentativas sequenciais,
enquanto o de espaço visa a proteger contra ataques que empregam \emph{hardware}
dedicado ou GPUs, caracterizados pelo paralelismo e escassez de memória.

Dessa forma, implementações eficientes de novos esquemas de \emph{hash} de
senhas, juntamente com suas análises de desempenho, são um tema recorrente
tanto no contexto do \emph{Password Hashing Competition}\footnote{\url{https://password-hashing.net/}}
\cite{cryptoeprint:2015:678} quanto no trabalho de pesquisadores externos
\cite{chang2015performance}, uma vez que tais resultados fornecem embasamento
para a escolha de parâmetros do esquema e para que se estimem suas garantias de
segurança quando empregado em ambientes diversos de \emph{hardware} e
\emph{software}.

Neste trabalho, foi produzida uma implementação do
esquema de \emph{hash} de senhas Lyra2, proposta por pesquisadores
brasileiros e finalista do \emph{Password Hashing Competition}, aproveitando
conjuntos de instruções presentes em arquiteturas modernas. Acredita-se
que o Lyra2 possua as propriedades de segurança exigidas de um esquema moderno
de \emph{hash} de senhas, e sua especificação inclui parâmetros de espaço e tempo
independentes a serem respeitados por uma implementação correta.
A implementação resultante\footnote{Disponível em \url{https://github.com/guilherme-pg/lyra2}}
é compatível com a de referência e competitiva em termos de desempenho. Houve colaboração
ainda com o desenvolvimento da especificação do Lyra2 \cite{lyra2-spec},
na medida em que este trabalho trouxe à tona diversas
inconsistências no documento de especificação e na implementação de referência.

A implementação proposta possui duas variantes: uma utilizando as instruções
vetoriais do conjunto SSE2, e outra utilizando as do conjunto AVX2. Como o
código de referência possui versões genérica (sem instruções vetoriais) e SSE2,
cabe clarificar que, para o restante deste documento, quaisquer menções à
implementação proposta ou à de referência se aplicam às respectivas versões
SSE2 (a não ser, é claro, que a versão AVX2 deste trabalho esteja sendo
discutida).

\section{Notação}

Para o restante deste documento, os símbolos da primeira coluna da
Tabela~\ref{tb:notation} a seguir serão usados com o significado dado pela segunda coluna.

\begingroup
\small
\begin{longtable}[c]{@{}cc@{}}
\toprule
Símbolo & Significado\tabularnewline
\midrule
\endhead
$\oplus$ & XOR bit-a-bit\tabularnewline
$\lfloor \cdot \rfloor l$ & Truncagem para $l$ \emph{bits}\tabularnewline
$\ggg n$ & Rotação $n$ \emph{bits} à direita\tabularnewline
$\boxplus$ & Adição sem carry entre palavras\tabularnewline
$||$ & Concatenação\tabularnewline
$len(n)$ & Tamanho em \emph{bytes} de $n$\tabularnewline
$LSW(n)$ & Palavra menos significativa de $n$\tabularnewline
$rotRt(n)$ & Rotação $Rt$ \emph{bits} à direita de $n$\tabularnewline
$rotRt^{m}(n)$ & Rotação $m \cdot Rt$ \emph{bits} à direita de
$n$\tabularnewline
\bottomrule
\caption{\label{tb:notation} Notação utilizada neste trabalho.}
\end{longtable}
\vspace{-1cm}
\endgroup

\section{O esquema de hash Lyra2}

O Lyra2 se baseia na construção de esponja, uma forma geral para a
geração de funções de \emph{hash} seguras com entradas e saídas de
tamanhos arbitrários a partir de uma função de compressão e um esquema
de \emph{padding}. De fato, o cálculo do Lyra2 para uma determinada entrada pode ser
descrito em alto nível como a aplicação iterada de operações de esponja,
a serem descritas a seguir, a dados mantidos em uma matriz de estado do
algoritmo. Consequentemente, conjectura-se que as propriedades de
segurança do Lyra2 decorrem tanto da segurança da esponja subjacente,
quanto da escolha criteriosa de operações de esponja empregadas, que
dificulta a paralelização do algoritmo.

\subsection{A construção de esponja}

A definição canônica de uma esponja \cite{sponge} descreve sua operação
em termos de duas etapas -- \emph{absorbing} e \emph{squeezing} --,
sendo que na primeira a esponja incorpora a entrada a seu estado
interno, e na segunda produz uma saída do tamanho desejado baseada nesse
estado. Assim, ao final de uma etapa de \emph{squeezing}, a esponja terá
produzido um \emph{hash} pseudoaleatório de sua entrada, e pode ser
restaurada a seu estado original para uma aplicação posterior.

A Figura \ref{img-sponge} ilustra a construção de esponja. Nela, a
entrada $M$ é dividida em blocos após o \emph{padding} e absorvida
para gerar a saída $Z$. A função $f$ é uma função de compressão. A linha
tracejada separa as etapas de \emph{absorbing} (esquerda) e
\emph{squeezing} (direita), e o estado interno da esponja é dividido em
duas partes com tamanhos $r$ (taxa) e $c$ (capacidade)
\emph{bits}.

\begin{figure}[htbp]
\centering
\includegraphics[scale=0.75]{./img/sponge.png}
\caption{A construção de esponja, adaptado de~\cite{sponge}.\label{img-sponge}}
\end{figure}

Pode-se definir, ainda, uma construção similar à da esponja, denominada
\emph{duplex}, em que se mantém o estado interno entre aplicações. Nela, as
operações de \emph{absorb} e \emph{squeeze} são substituídas por uma operação
de \emph{duplexing}, na qual um bloco de entrada passa por \emph{padding}
individualmente, é absorvido, e um bloco de saída é imediatamente produzido. A
Figura \ref{img-duplex} ilustra a construção de \emph{duplex}.

\begin{figure}[htbp]
\centering
\includegraphics{./img/duplex.png}
\caption{A construção de duplex, adaptado de~\cite{sponge}.\label{img-duplex}}
\end{figure}

Embora semelhantes, esponja e \emph{duplex} são tipicamente tratadas como
construções distintas na literatura \cite{sponge} e em implementações
\footnote{A exemplo da implementação de referência da Keccak (SHA-3), em
\url{https://github.com/gvanas/KeccakCodePackage}}. O Lyra2 utiliza uma versão
modificada da construção de \emph{duplex}, em que as operações de esponja
também são suportadas. Dessa forma, a esponja do Lyra2 é capaz de realizar
\emph{duplexing} de blocos individuais de tamanho $r$, bem como
\emph{absorbing} e \emph{squeezing} de entradas de tamanho arbitrário, e todas
essas operações compartilham o mesmo estado interno.

\subsection{A função de compressão}\label{sec-compression-fn}

Conforme visto anteriormente, a construção de esponja depende de uma função
$f$, denominada função de compressão. Para a esponja usada no Lyra2, a função
de compressão é uma versão levemente adaptada da função $G$ que integra a
função de \emph{hash} BLAKE2b \cite{blake2b}.
%
Especificamente, no Lyra2, são omitidos os parâmetros $m$ (mensagem) e $\sigma$
(índices para permutação da mensagem), e a função usa como entrada e saída
apenas os dados já presentes na matriz de estado. Dessa forma, a função $G(a,
b, c, d)$ utilizada é dada por
\begingroup
\setlength{\jot}{0.1pt}
\begin{align*}
& a \leftarrow a + b \\
& d \leftarrow \left(d \oplus a \right) \ggg 32 \\
& c \leftarrow c + d \\
& b \leftarrow \left(b \oplus c \right) \ggg 24 \\
& a \leftarrow a + b \\
& d \leftarrow \left(d \oplus a \right) \ggg 16 \\
& c \leftarrow c + d \\
& b \leftarrow \left(b \oplus c \right) \ggg 63
\end{align*}
\endgroup

No algoritmo BLAKE2b, a função é aplicada repetidamente a uma matriz de estado
$4 \times 4$ de inteiros de 64 \emph{bits}, primeiro aos elementos de cada
coluna, depois aos de cada diagonal. Essas oito aplicações constituem uma
\emph{rodada}, e o algoritmo faz transformações do estado em conjuntos de 12
rodadas por vez.

No Lyra2, o estado da esponja contém $128$ \emph{bytes} e é visto como uma matriz de
estado linearizada, e as rodadas são definidas de forma análoga. No entanto, a
fim de melhorar o desempenho do algoritmo, a maior parte das compressões
efetuadas pela esponja não utiliza $\rho_{max} = 12$ rodadas, mas sim $\rho <
\rho_{max}$ (na prática, utiliza-se $\rho = 1$). Tais operações com apenas
$\rho$ rodadas são denominadas operações \emph{reduzidas} da esponja.

\subsection{O algoritmo Lyra2 }\label{sec-lyra2-alg}

A Figura \ref{lyra2-alg} contém o pseudocódigo do algoritmo Lyra2 implementado
para este trabalho, correspondente à versão 2.5 da especificação. A versão 3.0,
a mais recente do algoritmo, funciona de forma bastante similar à descrita
nesta Seção, de forma que a implementação proposta pode ser facilmente
atualizada.

\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{./img/spec.pdf}
\caption{O algoritmo Lyra2 implementado neste trabalho\label{lyra2-alg}, conforme versão 2.5 da especificação~\cite{lyra2-spec}.}
\end{figure}

Conceitualmente, o algoritmo consiste de três etapas: \emph{bootstrapping},
\emph{setup} e \emph{wandering}. Todas elas trabalham sobre uma matriz
de estado de $R \times C$ blocos de $b$ \emph{bits}, onde $R$ e $C$
são, portanto, parâmetros de espaço.
%
O tamanho dos blocos é definido de forma que possam ser absorvidos sem
\emph{padding} pela esponja utilizada. Embora um bloco de $b = r$ \emph{bits}
pareça natural tendo em vista as Figuras \ref{img-sponge} e
\ref{img-duplex}, a especificação sugere aumentar $r$ após a primeira
absorção (linha 3 da Figura \ref{lyra2-alg}). Na prática, tanto no
código desenvolvido quanto no de referência utilizam um $r$ inicial de $512$ \emph{bits},
e utilizam posteriormente um novo $r = b = 768$ \emph{bits}.

A fase de \emph{bootstrapping} inicializa a esponja com o vetor de
inicialização da função de compressão, e então absorve os parâmetros de
entrada. A fase de \emph{setup} inicializa a matriz de estado, e a fase
de \emph{wandering} aplica operações reduzidas de esponja a células
pseudoaleatórias dessa matriz. Nessa fase, o parâmetro $T$ controla o
número de iterações a serem feitas, e, portanto, o tempo utilizado.
O tempo total de execução do algoritmo é dado por
$(T + 1) \cdot R \cdot C \cdot \frac{\rho}{\rho_{max}}$ vezes o tempo
de execução da função de compressão da esponja, de forma que, ainda que
o tempo de execução seja limitado inferiormente pelos parâmetros de
memória $R$ e $C$, ainda é possível aumentá-lo mantendo o consumo de
memória constante, através do parâmetro $T$.

\section{Descrição da implementação}\label{sec-impl}

A implementação proposta foi desenvolvida, tal como a de referência, utilizando
a linguagem C, mas com base em decisões de projeto levemente diferentes. Além
de prezar pelo desempenho, o trabalho foi desenvolvido com particular cuidado
pela legibilidade, facilitando eventuais auditorias do código, e portabilidade,
evitando-se utilizar extensões específicas de determinados compiladores e
aderindo-se de forma bastante estrita ao padrão C99.
%
Uma diferença particularmente perceptível entre as implementações é que,
enquanto a de referência utiliza largamente \emph{intrinsics} para obter
controle fino sobre as instruções geradas, a implementação mantém os
operadores de alto nível da linguagem C e delega ao compilador a tarefa
de emitir as instruções vetoriais para a maior parte do código, à
exceção da função de compressão. Além do benefício em legibilidade, essa
decisão tornou prático emitir versões utilizando diferentes conjuntos de
instruções usando o mesmo código, e, conforme a Seção
\ref{sec-experimental}, não trouxe perda de desempenho significativa.

O código utilizado para a função de compressão é o da implementação de
referência da BLAKE2b \footnote{Disponível em
  \url{https://github.com/BLAKE2/BLAKE2}}, com pequenas adaptações para
remover as constantes utilizadas durante aplicações da função $G$. No
entanto, como essa implementação da BLAKE2b não possui versão AVX2, foi
necessário adaptá-la conforme descrito na Subseção \ref{sec-compression-fn-avx2}
para que utilizasse esse conjunto de instruções.

O algoritmo Lyra2 apresentado na Subseção \ref{sec-lyra2-alg} não
especifica o parâmetro $Rt$, que determina o tamanho em \emph{bits} das
rotações de blocos; a implementação de referência, em sua versão SSE2,
utiliza $Rt = 128$ \emph{bits}, dado que este é o tamanho de um vetor SSE2.
Da mesma forma, o trabalho usa $Rt = 128$ quando compilado com
SSE2, e $Rt = 256$ em sua versão AVX2.

\subsection{A função de compressão em AVX2 }\label{sec-compression-fn-avx2}

Esta Seção detalha as mudanças feitas na implementação de referência da
função de compressão do Lyra2 para aproveitar as instruções vetoriais do
conjunto AVX2.

Conforme exposto na Subseção \ref{sec-compression-fn}, a função de
compressão $f$ do Lyra2 executa $\rho$ rodadas da função $G$ sobre uma
matriz de estado $4 \times 4$ de $64$ \emph{bits}. Assim, para uma matriz
da forma
\begin{align*}
\left(
\begin{matrix}
v_{0} & v_{1} & v_{2} & v_{3} \\
v_{4} & v_{5} & v_{6} & v_{7} \\
v_{8} & v_{9} & v_{10} & v_{11} \\
v_{12} & v_{13} & v_{14} & v_{15}
\end{matrix}
\right),
\end{align*}
uma rodada corresponde a:
\begin{align*}
\begin{matrix}
G(v_{0}, v_{4}, v_{8}, v_{12}) & G(v_{1}, v_{5}, v_{9}, v_{13}) & G(v_{2}, v_{6}, v_{10}, v_{14}) & G(v_{3}, v_{7}, v_{11}, v_{15}) \\
G(v_{0}, v_{5}, v_{10}, v_{15}) & G(v_{1}, v_{6}, v_{11}, v_{12}) & G(v_{2}, v_{7}, v_{8}, v_{13}) & G(v_{3}, v_{4}, v_{9}, v_{14})
\end{matrix}
\end{align*}
onde as aplicações em cada linha podem ocorrer em paralelo. No Lyra2, o estado
da esponja possui $16 \times 64 = 1024$ \emph{bits} e serve como uma
matriz de estado linearizada em ordem de linhas para a função de compressão.

Na implementação vetorizada de referência da BLAKE2b, cada registrador vetorial
contém mais de um inteiro da matriz de estado -- por exemplo, com SSE2, $v_{0}$
e $v_{1}$ compartilham um vetor de $128$ \emph{bits}. Uma rodada consiste em
executar $G$ sobre as linhas da matriz em paralelo, então
\emph{diagonalizá-la}, rotacionando a $i$-ésima linha $i$ posições à esquerda,
transformando as diagonais em colunas, aplicar a função $G$ sobre as (novas)
colunas, e desfazer as rotações~\cite{blake2b}.

Essas mesmas técnicas podem ser usadas em uma versão AVX2 de $f$, em que
cada registrador de $256$ \emph{bits} comporta uma linha inteira da matriz. O
código AVX2 produzido para este trabalho utiliza as novas instruções
\texttt{vpaddq} para as adições de $64$ \emph{bits}, \texttt{vpxor} para as
operações de XOR, \texttt{vpshufd} e \texttt{vpshufd} para as rotações, e
\texttt{vpermq} para as rotações de linhas da matriz.
%
No código, a implementação AVX2 possui a mesma estrutura geral que a de
referência, apesar dos \emph{intrinsics} diferentes. A função $G$ é dividida em
duas partes: G1 contém as instruções até a operação $\ggg 24$, e G2 contém o
restante da função, conforme a listagem a seguir:

\hspace{-1.5cm}\begin{tabular}{c|c}
\begin{minipage}{0.5\textwidth}
\begin{small}
\begin{verbatim}
#define G1(r1,r2,r3,r4)             \
  row1 = _mm256_add_epi64(r2, r2);  \
  row4 = _mm256_xor_si256(r4, r1);  \
  row4 = _mm256_roti_epi64(r4, -32);\
  row3 = _mm256_add_epi64(r3, r4);  \
  row2 = _mm256_xor_si256(r2, r3);  \
  row2 = _mm256_roti_epi64(r2, -24);\
\end{verbatim}
\end{small}
\end{minipage} &
\begin{minipage}{0.5\textwidth}
\begin{small}
\begin{verbatim}
#define G2(r1,r2,r3,r4)             \
  row1 = _mm256_add_epi64(r1, r2);  \
  row4 = _mm256_xor_si256(r4, r1);  \
  row4 = _mm256_roti_epi64(r4, -16);\
  row3 = _mm256_add_epi64(r3, r4);  \
  row2 = _mm256_xor_si256(r2, r3);  \
  row2 = _mm256_roti_epi64(r2, -63);\
\end{verbatim}
\end{small}
\end{minipage}
\end{tabular}

Na listagem, \texttt{\_mm256\_roti\_epi64}, responsável pelas rotações, é a
única primitiva que não é um \emph{intrinsic}. Essa macro é definida como:

\begin{small}
\begin{verbatim}
#define r16_256 _mm256_setr_epi8(                              \
    2, 3, 4, 5, 6, 7, 0, 1, 10, 11, 12, 13, 14, 15, 8, 9, 18,  \
    19, 20, 21, 22, 23, 16, 17, 26, 27, 28, 29, 30, 31, 24, 25)
#define r24_256 _mm256_setr_epi8(                              \
    3, 4, 5, 6, 7, 0, 1, 2, 11,12, 13, 14, 15, 8, 9, 10, 19,   \
    20, 21, 22, 23, 16, 17, 18, 27, 28, 29, 30, 31, 24, 25, 26)
\end{verbatim}
\end{small}

\begin{small}
\begin{verbatim}
#define _mm256_roti_epi64(x, c)                                    \
    (-(c) == 32) ? _mm256_shuffle_epi32((x), _MM_SHUFFLE(2,3,0,1)) \
    : (-(c) == 24) ? _mm256_shuffle_epi8((x), r24_256)             \
    : (-(c) == 16) ? _mm256_shuffle_epi8((x), r16_256)             \
    : (-(c) == 63) ? _mm256_xor_si256(_mm256_srli_epi64((x), -(c)),\
                                      _mm256_add_epi64((x), (x)))  \
    : _mm256_xor_si256(_mm256_srli_epi64((x), -(c)),               \
                       _mm256_slli_epi64((x), 64-(-(c))))}
\end{verbatim}
\end{small}

A diagonalização e sua inversa são implementadas a partir do \emph{intrinsic}
de permutação de palavras \texttt{\_mm256\_permute4x64\_epi64}, definido como abaixo:

\begin{small}
\begin{verbatim}
#define DIAGONALIZE(row1, row2, row3, row4)                   \
  row2 = _mm256_permute4x64_epi64(row2, _MM_SHUFFLE(0,3,2,1));\
  row3 = _mm256_permute4x64_epi64(row3, _MM_SHUFFLE(1,0,3,2));\
  row4 = _mm256_permute4x64_epi64(row4, _MM_SHUFFLE(2,1,0,3));}

#define UNDIAGONALIZE(row1, row2, row3, row4)                 \
  row2 = _mm256_permute4x64_epi64(row2, _MM_SHUFFLE(2,1,0,3));\
  row3 = _mm256_permute4x64_epi64(row3, _MM_SHUFFLE(1,0,3,2));\
  row4 = _mm256_permute4x64_epi64(row4, _MM_SHUFFLE(0,3,2,1));}
\end{verbatim}
\end{small}

E, assim, uma rodada é definida como:

\begin{small}
\begin{verbatim}
#define BLAKE2B_ROUND(v)                \
  G1(v[0], v[1], v[2], v[3]);           \
  G2(v[0], v[1], v[2], v[3]);           \
  DIAGONALIZE(v[0], v[1], v[2], v[3]);  \
  G1(v[0], v[1], v[2], v[3]);           \
  G2(v[0], v[1], v[2], v[3]);           \
  UNDIAGONALIZE(v[0], v[1], v[2], v[3]);}
\end{verbatim}
\end{small}
onde o parâmetro \texttt{v} é uma matriz de estado linearizada, de forma
que \texttt{v[i]} é um \texttt{\_\_m256i} contendo a $i$-ésima linha.

Além das adaptações em $f$, as únicas mudanças não-triviais feitas no restante
do código para habilitar o uso do conjunto de instruções AVX2 correspondem aos
requerimentos de alinhamento de memória nos operandos das novas instruções.

\section{Contribuições para a implementação de referência }
\label{sec-contribuicoes}

A adoção de um tamanho $R_{t}$ para as rotações de bits independente de $W$ no
Algoritmo \ref{lyra2-alg} decorre deste trabalho, após observar-se que o código
compilado de referência implementava o operando $\boxplus$ como adição palavra
a palavra de $64$ \emph{bits}, embora a intenção inicial dos autores da
especificação fosse efetuar adições módulo $2^{W}$, com $W = 128$ \emph{bits}
em SSE2. A distinção entre $R_{t}$ e $W$ permite implementar adições e rotações
de forma eficiente e bem definida na presença de instruções vetoriais.

Este trabalho revelou ainda outros problemas menores na especificação, como o
uso de um índice incorretos no acesso a células da matriz de estado no
algoritmo. Foram encontrados ainda diversos \emph{bugs} na implementação de
referência, como uma implementação incorreta do operador $LSW(n)$ e a
initialização de colunas em ordem incorreta no \emph{Filling loop} do Algoritmo
\ref{lyra2-alg}.

\section{Resultados experimentais }
\label{sec-experimental}

Esta Seção apresenta uma comparação de desempenho entre diferentes
implementações do Lyra2. Os testes foram conduzidos em dois ambientes: um
Macbook Pro Retina Mid-2012, sistema operacional OSX 10.10.4, com um
processador Intel Core i7-3720QM (Ivy Bridge) e 16 GiB de memória, e uma
máquina com processador Intel Core i7-4770 (Haswell) e 8GiB de memória e
distribuição Linux Fedora 18. O recurso TurboBoost, que aumenta dinamicamente a
frequência do processador, foi desativado em ambas.

Cada implementação foi executada $1000$ vezes em prioridade normal com as
mesmas entradas e uma saída $64$ \emph{bytes}, para três conjuntos de parâmetros $R$ e
$T$ do Lyra2, mantendo-se $C = 256$, valor sugerido pela implementação de
referência. A mediana dos tempos dessas execuções foi tomada como métrica final
de desempenho para cada conjunto de parâmetros.

Para cada código, testaram-se os binários gerados pelos compiladores LLVM 3.4.2
e GCC 4.9.0, avaliando-se assim a escolha desta implementação de delegar a maior parte
das escolhas de instruções para o compilador, conforme a Seção \ref{sec-impl}.
No entanto, devido ao limitado suporte ao GCC em OSX, apenas medições com LLVM
foram feitas nessa plataforma. Na implementação de referência, as opções de
compilação \begin{small}\verb|-flto|\end{small},
\begin{small}\verb|-mprefer-avx128|\end{small} e
\begin{small}\verb|-ftree-vectorizer-verbose|\end{small} foram desativadas sob
LLVM: a primeira causou erros de ligação em Linux, e as demais não são
suportadas.

A Figura \ref{results-linux} ilustra os resultados experimentais obtidos no
ambiente Linux. Nela, os nomes \emph{ref-gcc} e \emph{ref-clang} correspondem à
implementação de referência compilada, respectivamente, com GCC e LLVM. Os
nomes \emph{gcc} e \emph{clang} são análogos, mas referem-se à implementação
deste trabalho. Finalmente, \emph{avx2-clang} e \emph{avx2-gcc} correspondem à
variante com instruções AVX2, descrita na Subseção
\ref{sec-compression-fn-avx2}. Os tempos de execução foram normalizados pelo da
medição \emph{ref-gcc} em cada teste.

\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{./img/linux.png}
\caption{Tempos de execução normalizados para as três configurações de parâmetros em Linux\label{results-linux}.}
\end{figure}

As versões AVX2, conforme esperado, foram superiores às demais. Nelas, o
compilador utilizado não trouxe diferença significativa (\emph{avx2-clang} foi
apenas cerca de $3\%$ mais rápida do que \emph{avx2-gcc} em todos os testes), e
ambas foram cerca de $30\%$ mais rápidas do que \emph{ref-gcc} em todos os
testes. Os desvios padrão ficaram abaixo de $0.5\%$ da mediana em todas as
medições.
%
Entre as versões SSE2, \emph{clang} foi consistentemente a mais rápida, com
desempenho cerca de $17\%$ superior a \emph{ref-gcc}. Observou-se a maior
diferença com $R = T = 16$, em que \emph{clang} foi $17.76\%$ mais rápida do
que \emph{ref-gcc} ($1445 \mu s$ contra $1757 \mu s$). Novamente, os desvios
padrão foram inferiores a $0.5\%$ das medianas.

Em todos os testes, \emph{ref-clang} foi cerca de $9\%$ mais lenta do que
\emph{ref-gcc}, enquanto que, na implementação deste trabalho, a influência foi
contrária e de menor magnitude: \emph{gcc} foi apenas $1.5\%$ mais lenta do que
\emph{clang}. Como esta implementação foi desenvolvida no ambiente com OSX e
LLVM, e a de referência em ambiente Linux com GCC, essas discrepâncias refletem
a maior exposição de cada implementação à plataforma em que foi escrita.

A Figura \ref{results-osx} mostra os resultados dos mesmos testes executados na
máquina rodando OSX. Esse \emph{hardware} não oferece instruções AVX2, de forma
que não foi possível avaliar \emph{avx2-clang}. O binário \emph{clang} foi
cerca de $25\%$ mais rápido do que \emph{ref-clang} em todos os testes.

\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{./img/osx.png}
\caption{Tempos de execução normalizados para as três configurações de
parâmetros em OSX\label{results-osx}.}
\end{figure}

Cabe notar que, neste ambiente, os desvios padrão foram maiores do que em Linux
para ambas as implementações. No teste de maior diferença relativa, $R = T =
16$, \emph{clang} foi $26.76\%$ mais rápida ($1888 \mu s$ contra $2578 \mu s$),
com desvios padrão de $21.90 \mu s$ e $35.34 \mu s$, respectivamente. Para $R =
T = 64$, \emph{clang} teve alto desvio padrão ($177.39 \mu s$, contra $121.31
\mu s$ de \emph{ref-clang}), mas desempenho ainda $25.31\%$ melhor.

\section{Conclusão}

Este trabalho propõe uma implementação de um novo esquema de \emph{hash} de
senhas que supera a de referência em desempenho empregando instruções AVX2,
além de ter contribuído com a especificação. O estudo da eficiência de
primitivas desse tipo é importante pois orienta escolhas de parâmetros e
estimativas de níveis de segurança.

\bibliographystyle{sbc}
\bibliography{lyra2}

\end{document}
